The results of the classification algorithm show that this method can be realistically used within a web-browser. Since it rarely ever classifies useful content as an advertisement, the worst case scenario results in advertisements showing rather than blocking desired information. To further enhance the proof-of-concept, the Python script and Matlab can be linked through a web interface as discussed earlier. A better way to encapsulate the system would be to implement the TreeBager algorithm in Python using SciKit-Learn which would allow both webscraping and classification within Python. Furthermore, a web-application can be made using Django or Flask to demonstrate the functionality of the algorithm. 

Beyond just proof-of-concept, this method of advertisement classification has realisitic potential. The TreeBagger can be trained offline and implemented as a browser plugin, which would automatically block images classified as advertisements. The raw HTML would be first parsed by the plugin and the filtered webpage would be displayed to the user. Ideally, the initial HTML response would be parsed before the images are downloaded, preventing the unncessary request for irrelevant images. 

One major problem with web scraping is that not all advertisements strictly fit the specified format. Some websites omit certain data from advertisements, and some generate HTML using JavaScript, which is not handled by BeautifulSoup. This is a major issue with our system. This problem could be solved by better HTML parsers that handle JavaScript and a more general approach to feature extraction that does not care about missing data.

Additional future work could also include selection of features which better characterize advertisements on the internet as we found that the existing dataset did not use features that heuristically seem optimal.